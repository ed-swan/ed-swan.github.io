<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html lang="en" xml:lang="en">
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="StyleSheet" href="../css/responsive.css" type="text/css" media="all">
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>J. Edward Swan II</title>
</head>
<body><div class="outer_wrapper"><div class="inner_wrapper">
<div class="header"><p>J. Edward Swan II</p></div>
<div class="menu">
<ul>
<li><a href="../index.html"><em>A</em>BOUT</a></li> •
           <li><a href="../research.html"><em>R</em>ESEARCH</a></li> •
           <li><a href="sort_date.html" class="selected"><em>P</em>UBLICATIONS</a></li> •
           <li><a href="../teaching.html"><em>T</em>EACHING</a></li> •
           <li><a href="../tutorials.html"><em>T</em>UTORIALS</a></li> •
           <li><a href="../students.html"><em>S</em>TUDENTS</a></li>
</ul>
<p> </p>
</div>
<div class="content">
<ul class="h_list">
<li><big>• <a href="class_rescat.html">Classified by Research Category</a> </big></li>
<li><big>• <a href="class_type.html">Classified by Publication Type</a> </big></li>
<li><big>• <a href="sort_date.html">Classified by Date</a> </big></li>
</ul>
<h2> A Perceptual Matching Technique for Depth Judgments in Optical,                 See-Through Augmented Reality</h2>
<p class="citation"> J. Edward Swan&nbsp;II,  Mark A. Livingston,  Harvey S. Smallman,  Dennis Brown,  Yohan Baillot,  Joseph L. Gabbard, and  Deborah Hix.  A Perceptual Matching Technique for Depth Judgments in Optical,                 See-Through Augmented Reality. In <i> Technical Papers, Proceedings of IEEE Virtual Reality 2006</i>, pp. 19&ndash;26,  IEEE Computer Society, March 2006.<br />  <b>Winner of an Honorable Mention award at IEEE Virtual Reality 2006</b>.</p>
<h3>Download</h3>
<p><a href="papers/2006_Swan-etal_Matching-Technique-IEEE-VR.pdf">[PDF]</a>&nbsp;</p>
<h3>Abstract</h3>
<p class="abstract">  A fundamental problem in optical, see-through augmented reality (AR) is characterizing how it affects the perception of spatial layout and depth.  This problem is important because AR system developers need to both place graphics in arbitrary spatial relationships with real-world objects, and to know that users will perceive them in the same relationships.  Fur-thermore, AR makes possible enhanced perceptual techniques that have no real-world equivalent, such as x-ray vision, where AR users are supposed to perceive graphics as being located behind opaque surfaces. This paper reviews and discusses techniques for measuring egocentric depth judgments in both virtual and augmented envi-ronments.  It then describes a perceptual matching task and experimental design for measuring egocentric AR depth judgments at medium- and far-field distances of 5 to 45 meters.  The experiment studied the effect of field of view, the x-ray vision condition, multiple distances, and practice on the task.  The paper relates some of the findings to the well-known problem of depth underestimation in virtual environments, and further reports evidence for a switch in bias, from underestimating to overestimating the distance of AR-presented graphics, at &nbsp;23 meters.  It also gives a quantification of how much more difficult the x-ray vision condition makes the task, and then concludes with ideas for improving the experimental methodology. </p>
<h3>Additional Information</h3>
<p>Acceptance rate: 28% (27 out of 95), Award rate: 11% (3 out of 27)</p>
<a href="IEEEVR06-pmt.bib"><h3>BibTeX</h3></a><pre>@InProceedings{IEEEVR06-pmt, 
  author =      {J. Edward {Swan~II} and Mark A. Livingston and Harvey S. Smallman and 
                Dennis Brown and Yohan Baillot and Joseph L. Gabbard and Deborah Hix}, 
  title =       {A Perceptual Matching Technique for Depth Judgments in Optical, 
                See-Through Augmented Reality}, 
  booktitle =   {Technical Papers, Proceedings of IEEE Virtual Reality 2006}, 
  year =        2006, 
  location =    {Alexandria, Virginia, USA}, 
  date =        {March 25--29}, 
  month =       {March}, 
  publisher =   {IEEE Computer Society}, 
  pages =       {19--26}, 
  wwwnote =     {&lt;b&gt;Winner of an Honorable Mention award at IEEE Virtual Reality 2006&lt;/b&gt;.}, 
  abstract =    { 
A fundamental problem in optical, see-through augmented reality (AR) 
is characterizing how it affects the perception of spatial layout and 
depth.  This problem is important because AR system developers need to 
both place graphics in arbitrary spatial relationships with real-world 
objects, and to know that users will perceive them in the same 
relationships.  Fur-thermore, AR makes possible enhanced perceptual 
techniques that have no real-world equivalent, such as x-ray vision, 
where AR users are supposed to perceive graphics as being located 
behind opaque surfaces. 
This paper reviews and discusses techniques for measuring egocentric 
depth judgments in both virtual and augmented envi-ronments.  It then 
describes a perceptual matching task and experimental design for 
measuring egocentric AR depth judgments at medium- and far-field 
distances of 5 to 45 meters.  The experiment studied the effect of 
field of view, the x-ray vision condition, multiple distances, and 
practice on the task.  The paper relates some of the findings to the 
well-known problem of depth underestimation in virtual environments, 
and further reports evidence for a switch in bias, from 
underestimating to overestimating the distance of AR-presented 
graphics, at ~23 meters.  It also gives a quantification of how much 
more difficult the x-ray vision condition makes the task, and then 
concludes with ideas for improving the experimental methodology. 
}, 
} 
</pre>
</div>
</div></div></body>
</html>
