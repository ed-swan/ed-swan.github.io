<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html lang="en" xml:lang="en">
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="StyleSheet" href="../css/responsive.css" type="text/css" media="all">
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>J. Edward Swan II</title>
</head>
<body><div class="outer_wrapper"><div class="inner_wrapper">
<div class="header"><p>J. Edward Swan II</p></div>
<div class="menu">
<ul>
<li><a href="../index.html"><em>A</em>BOUT</a></li> •
           <li><a href="../research.html"><em>R</em>ESEARCH</a></li> •
           <li><a href="sort_date.html" class="selected"><em>P</em>UBLICATIONS</a></li> •
           <li><a href="../teaching.html"><em>T</em>EACHING</a></li> •
           <li><a href="../tutorials.html"><em>T</em>UTORIALS</a></li> •
           <li><a href="../students.html"><em>S</em>TUDENTS</a></li>
</ul>
<p> </p>
</div>
<div class="content">
<ul class="h_list">
<li><big>• <a href="class_rescat.html">Classified by Research Category</a> </big></li>
<li><big>• <a href="class_type.html">Classified by Publication Type</a> </big></li>
<li><big>• <a href="sort_date.html">Classified by Date</a> </big></li>
</ul>
<h2> Resolving Multiple Occluded Layers in Augmented Reality</h2>
<p class="citation"> Mark A. Livingston,  J. Edward Swan&nbsp;II,  Joseph L. Gabbard,  Tobias H. H&ouml;llerer,  Deborah Hix,  Simon J. Julier,  Yohan Baillot, and  Dennis Brown.  Resolving Multiple Occluded Layers in Augmented Reality. In <i> Technical Papers, The IEEE / ACM International Symposium on Mixed and                 Augmented Reality (ISMAR 2003)</i>, pp. 56&ndash;65,  IEEE Computer Society, October 2003.<br />  <b>Winner of a 2004 NRL Alan Berman Publication Award</b>.</p>
<h3>Download</h3>
<p><a href="papers/2003_Livingston-Swan_Occluded-Layers_ISMAR.pdf">[PDF]</a>&nbsp;</p>
<h3>Abstract</h3>
<p class="abstract">  A useful function of augmented reality (AR) systems is their ability to visualize occluded infrastructure directly in a user's view of the environment.  This is especially important for our application context, which utilizes mobile AR for navigation and other operations in an urban environment.  A key problem in the AR field is how to best depict occluded objects in such a way that the viewer can correctly infer the depth relationships between different physical and virtual objects.  Showing a single occluded object with no depth context presents an ambiguous picture to the user.  But showing all occluded objects in the environments leads to the "Superman's X-ray vision" problem, in which the user sees too much information to make sense of the depth relationships of objects. Our efforts differ qualitatively from previous work in AR occlusion, because our application domain involves <em>far-field</em> occluded objects, which are tens of meters distant from the user.  Previous work has focused on <em>near-field</em> occluded objects, which are within or just beyond arm's reach, and which use different perceptual cues. We designed and evaluated a number of sets of display attributes.  We then conducted a user study to determine which representations best express occlusion relationships among far-field objects.  We identify a drawing style and opacity settings that enable the user to accurately interpret three layers of occluded objects, even in the absence of perspective constraints. </p>
<h3>Additional Information</h3>
<p>Acceptance rate: 33% (25 out of 75), Award rate: 3% (35 such awards were given, out of 1106 NRL publications)</p>
<a href="ISMAR03-mol.bib"><h3>BibTeX</h3></a><pre>@InProceedings{ISMAR03-mol, 
  author =      {Mark A. Livingston and J. Edward {Swan~II} and Joseph L. Gabbard and 
                Tobias H. H\"{o}llerer and Deborah Hix and Simon J. Julier and Yohan Baillot and 
                Dennis Brown}, 
  title =       {Resolving Multiple Occluded Layers in Augmented Reality}, 
  booktitle =   {Technical Papers, The IEEE / ACM International Symposium on Mixed and 
                Augmented Reality (ISMAR 2003)}, 
  year =        2003, 
  location =    {Tokyo, Japan}, 
  date =        {October 7--10}, 
  month =       {October}, 
  pages =       {56--65}, 
  publisher =   {IEEE Computer Society}, 
  wwwnote =     {&lt;b&gt;Winner of a 2004 NRL Alan Berman Publication Award&lt;/b&gt;.}, 
  abstract =    { 
A useful function of augmented reality (AR) systems is their ability 
to visualize occluded infrastructure directly in a user's view of the 
environment.  This is especially important for our application 
context, which utilizes mobile AR for navigation and other operations 
in an urban environment.  A key problem in the AR field is how to best 
depict occluded objects in such a way that the viewer can correctly 
infer the depth relationships between different physical and virtual 
objects.  Showing a single occluded object with no depth context 
presents an ambiguous picture to the user.  But showing all occluded 
objects in the environments leads to the "Superman's X-ray vision" 
problem, in which the user sees too much information to make sense of 
the depth relationships of objects. 
Our efforts differ qualitatively from previous work in AR occlusion, 
because our application domain involves &lt;em&gt;far-field&lt;/em&gt; occluded 
objects, which are tens of meters distant from the user.  Previous 
work has focused on &lt;em&gt;near-field&lt;/em&gt; occluded objects, which are within 
or just beyond arm's reach, and which use different perceptual cues. 
We designed and evaluated a number of sets of display attributes.  We 
then conducted a user study to determine which representations best 
express occlusion relationships among far-field objects.  We identify 
a drawing style and opacity settings that enable the user to 
accurately interpret three layers of occluded objects, even in the 
absence of perspective constraints. 
}, 
} 
</pre>
</div>
</div></div></body>
</html>
