<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html lang="en" xml:lang="en">
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="StyleSheet" href="../css/responsive.css" type="text/css" media="all">
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>J. Edward Swan II</title>
</head>
<body><div class="outer_wrapper"><div class="inner_wrapper">
<div class="header"><p>J. Edward Swan II</p></div>
<div class="menu">
<ul>
<li><a href="../index.html"><em>A</em>BOUT</a></li> •
           <li><a href="../research.html"><em>R</em>ESEARCH</a></li> •
           <li><a href="sort_date.html" class="selected"><em>P</em>UBLICATIONS</a></li> •
           <li><a href="../teaching.html"><em>T</em>EACHING</a></li> •
           <li><a href="../tutorials.html"><em>T</em>UTORIALS</a></li> •
           <li><a href="../students.html"><em>S</em>TUDENTS</a></li>
</ul>
<p> </p>
</div>
<div class="content">
<ul class="h_list">
<li><big>• <a href="class_rescat.html">Classified by Research Category</a> </big></li>
<li><big>• <a href="class_type.html">Classified by Publication Type</a> </big></li>
<li><big>• <a href="sort_date.html">Classified by Date</a> </big></li>
</ul>
<h2> Spatial Relationship-Driven Computer Vision Image Data Set                 Annotation</h2>
<p class="citation"> Jeremy Davis,  James B. Haynie,  Derek T. Anderson,  Cindy L. Bethel,  J. Edward Swan&nbsp;II,  John E. Ball, and  Amy Bednar.  Spatial Relationship-Driven Computer Vision Image Data Set                 Annotation. In <i> IEEE International Joint Conference on Neural Networks (IJCNN)</i>,  IEEE, July 2022.  DOI: <a target="_blank"                 href="https://doi.org/10.1109/IJCNN55064.2022.9892975">                 10.1109/IJCNN55064.2022.9892975</a>.</p>
<h3>Download</h3>
<p><a href="papers/2022_Davis-et-al_Spatial-Relationship-CV_IJCNN.pdf">[PDF]</a>&nbsp;</p>
<h3>Abstract</h3>
<p class="abstract"> Modern machine learning (ML) is based to a great extent on supervised deep learning models that require large amounts of labeled training data. While image data sets with annotations exist, the annotations are produced manually and possess relatively simple descriptions.  To date, none of the freely available labeled image data sets incorporate spatial reasoning, one of Gardner's nine human intelligences.  This article presents a new process with open source tools provided to label imagery based on spatial interactions between image objects and automated reasoning under uncertainty. The resulting annotated data can be used to train new ML/AI algorithms and/or help us better understand existing methodologies. </p>
<a href="IJCNN22.bib"><h3>BibTeX</h3></a><pre>@InProceedings{IJCNN22, 
  author =      {Jeremy Davis and James B. Haynie and Derek T. Anderson and
                 Cindy L. Bethel and J. Edward {Swan~II} and John E. Ball
                 and Amy Bednar},
  title =       {Spatial Relationship-Driven Computer Vision Image Data Set
                 Annotation},
  booktitle =   {IEEE International Joint Conference on Neural Networks (IJCNN)},
  year =        2022,
  location =    {Padova, Italy},
  publisher =   {IEEE}, 
  date =        {July 18--23}, 
  month =       {July}, 
  note =        {DOI: &lt;a target="_blank"
                 href="https://doi.org/10.1109/IJCNN55064.2022.9892975"&gt;
                 10.1109/IJCNN55064.2022.9892975&lt;/a&gt;.}
  abstract =    {
Modern machine learning (ML) is based to a great extent on supervised deep 
learning models that require large amounts of labeled training data. While image 
data sets with annotations exist, the annotations are produced manually and 
possess relatively simple descriptions.  To date, none of the freely available 
labeled image data sets incorporate spatial reasoning, one of Gardner's nine 
human intelligences.  This article presents a new process with open source tools 
provided to label imagery based on spatial interactions between image objects 
and automated reasoning under uncertainty. The resulting annotated data can be 
used to train new ML/AI algorithms and/or help us better understand existing 
methodologies. 
}, 
} 
</pre>
</div>
</div></div></body>
</html>
