@COMMENT This file was generated by bib2html.pl <https://sourceforge.net/projects/bib2html/> version 0.94
@COMMENT written by Patrick Riley <http://sourceforge.net/users/patstg/>
@InProceedings{IEEEVR-scp, 
  author =      {Alexander Plopski and Kenneth R. Moser and Kiyoshi Kiyokawa and 
                 J. Edward {Swan~II} and Haruo Takemura},
  title =       {Spatial Consistency Perception in Optical and Video
                 See-Through Head-Mounted Augmentations}, 
  booktitle =   {Poster Abstracts, IEEE International Conference on Virtual Reality 
                 (IEEE VR 2016)}, 
  location =    {Clemson, South Carolina, USA}, 
  date =        {March 19--23}, 
  month =       {Mar}, 
  year =        2016, 
  pages =       {265--266}, 
  note =        {DOI: <a target="_blank"
                 href="https://doi.org/10.1109/VR.2016.7504755">10.1109/VR.2016.7504755</a>.}, 
  abstract =    { 
Correct spatial alignment is an essential requirement for convincing
augmented reality experiences. Registration error, caused by a variety
of systematic, environmental, and user influences decreases the
realism and utility of head mounted display AR applications. Focus is
often given to rigorous calibration and prediction methods seeking to
entirely remove misalignment error between virtual and real
content. Unfortunately, producing perfect registration is often simply
not possible. Our goal is to quantify the sensitivity of users to
registration error in these systems, and identify acceptability
thresholds at which users can no longer distinguish between the
spatial positioning of virtual and real objects. We simulate both
video see-through and optical see-through environments using a
projector system and experimentally measure user perception of virtual
content misalignment. Our results indicate that users are less
perceptive to rotational errors over all and that translational
accuracy is less important in optical see-through systems than in
video see-through.
}, 
} 
