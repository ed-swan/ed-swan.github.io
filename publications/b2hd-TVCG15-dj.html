<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html lang="en" xml:lang="en">
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="StyleSheet" href="../css/responsive.css" type="text/css" media="all">
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>J. Edward Swan II</title>
</head>
<body><div class="outer_wrapper"><div class="inner_wrapper">
<div class="header"><p>J. Edward Swan II</p></div>
<div class="menu">
<ul>
<li><a href="../index.html"><em>A</em>BOUT</a></li> •
           <li><a href="../research.html"><em>R</em>ESEARCH</a></li> •
           <li><a href="sort_date.html" class="selected"><em>P</em>UBLICATIONS</a></li> •
           <li><a href="../teaching.html"><em>T</em>EACHING</a></li> •
           <li><a href="../tutorials.html"><em>T</em>UTORIALS</a></li> •
           <li><a href="../students.html"><em>S</em>TUDENTS</a></li>
</ul>
<p> </p>
</div>
<div class="content">
<ul class="h_list">
<li><big>• <a href="class_rescat.html">Classified by Research Category</a> </big></li>
<li><big>• <a href="class_type.html">Classified by Publication Type</a> </big></li>
<li><big>• <a href="sort_date.html">Classified by Date</a> </big></li>
</ul>
<h2> Matching and Reaching Depth Judgments with Real and Augmented                   Reality Targets</h2>
<p class="citation"> J. Edward Swan&nbsp;II,  Gurjot Singh, and  Stephen R. Ellis.  Matching and Reaching Depth Judgments with Real and Augmented                   Reality Targets. <i> IEEE Transactions on Visualization and Computer Graphics,                   IEEE International Symposium on Mixed and Augmented Reality                   (ISMAR 2015)</i>,  21(11):1289&ndash;1298, 2015.  DOI: <a target="_blank"                  href="https://doi.org/10.1109/TVCG.2015.2459895">10.1109/TVCG.2015.2459895</a>.</p>
<h3>Download</h3>
<p><a href="papers/2015_Swan-Singh-Ellis_Matching-Reaching-Depth-Judge_IEEE-ISMAR-TVCG.pdf">[PDF]</a>&nbsp;</p>
<h3>Abstract</h3>
<p class="abstract">  Many compelling augmented reality (AR) applications require users to correctly perceive the location of virtual objects, some with accuracies as tight as 1 mm. However, measuring the perceived depth of AR objects at these accuracies has not yet been demonstrated. In this paper, we address this challenge by employing two different depth judgment methods, perceptual matching and blind reaching, in a series of three experiments, where observers judged the depth of real and AR target objects presented at reaching distances. Our experiments found that observers can accurately match the distance of a real target, but when viewing an AR target through collimating optics, their matches systematically overestimate the distance by 0.5 to 4.0 cm. However, these results can be explained by a model where the collimation causes the eyes' vergence angle to rotate outward by a constant angular amount. These findings give error bounds for using collimating AR displays at reaching distances, and suggest that for these applications, AR displays need to provide an adjustable focus. Our experiments further found that observers initially reach &nbsp;4 cm too short, but reaching accuracy improves with both consistent proprioception and corrective visual feedback, and eventually becomes nearly as accurate as matching. </p>
<a href="TVCG15-dj.bib"><h3>BibTeX</h3></a><pre>@Article{TVCG15-dj, 
  author =       {J. Edward {Swan~II} and Gurjot Singh and Stephen R. Ellis}, 
  title =        {Matching and Reaching Depth Judgments with Real and Augmented 
                  Reality Targets}, 
  journal =      {IEEE Transactions on Visualization and Computer Graphics, 
                  IEEE International Symposium on Mixed and Augmented Reality 
                  (ISMAR 2015)}, 
  volume =       21, 
  number =       11, 
  year =         2015, 
  pages =        {1289--1298}, 
  note =         {DOI: &lt;a target="_blank"
                  href="https://doi.org/10.1109/TVCG.2015.2459895"&gt;10.1109/TVCG.2015.2459895&lt;/a&gt;.} 
  abstract =     { 
Many compelling augmented reality (AR) applications require users to 
correctly perceive the location of virtual objects, some with 
accuracies as tight as 1 mm. However, measuring the perceived depth of 
AR objects at these accuracies has not yet been demonstrated. In this 
paper, we address this challenge by employing two different depth 
judgment methods, perceptual matching and blind reaching, in a series 
of three experiments, where observers judged the depth of real and AR 
target objects presented at reaching distances. Our experiments found 
that observers can accurately match the distance of a real target, but 
when viewing an AR target through collimating optics, their matches 
systematically overestimate the distance by 0.5 to 4.0 cm. However, 
these results can be explained by a model where the collimation causes 
the eyes' vergence angle to rotate outward by a constant angular 
amount. These findings give error bounds for using collimating AR 
displays at reaching distances, and suggest that for these 
applications, AR displays need to provide an adjustable focus. Our 
experiments further found that observers initially reach ~4 cm too 
short, but reaching accuracy improves with both consistent 
proprioception and corrective visual feedback, and eventually becomes 
nearly as accurate as matching. 
}, 
} 
</pre>
</div>
</div></div></body>
</html>
