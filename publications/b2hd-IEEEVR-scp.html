<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html lang="en" xml:lang="en">
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="StyleSheet" href="../css/responsive.css" type="text/css" media="all">
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>J. Edward Swan II</title>
</head>
<body><div class="outer_wrapper"><div class="inner_wrapper">
<div class="header"><p>J. Edward Swan II</p></div>
<div class="menu">
<ul>
<li><a href="../index.html"><em>A</em>BOUT</a></li> •
           <li><a href="../research.html"><em>R</em>ESEARCH</a></li> •
           <li><a href="sort_date.html" class="selected"><em>P</em>UBLICATIONS</a></li> •
           <li><a href="../teaching.html"><em>T</em>EACHING</a></li> •
           <li><a href="../tutorials.html"><em>T</em>UTORIALS</a></li> •
           <li><a href="../students.html"><em>S</em>TUDENTS</a></li>
</ul>
<p> </p>
</div>
<div class="content">
<ul class="h_list">
<li><big>• <a href="class_rescat.html">Classified by Research Category</a> </big></li>
<li><big>• <a href="class_type.html">Classified by Publication Type</a> </big></li>
<li><big>• <a href="sort_date.html">Classified by Date</a> </big></li>
</ul>
<h2> Spatial Consistency Perception in Optical and Video                 See-Through Head-Mounted Augmentations</h2>
<p class="citation"> Alexander Plopski,  Kenneth R. Moser,  Kiyoshi Kiyokawa,  J. Edward Swan&nbsp;II, and  Haruo Takemura.  Spatial Consistency Perception in Optical and Video                 See-Through Head-Mounted Augmentations. In <i> Poster Abstracts, IEEE International Conference on Virtual Reality                  (IEEE VR 2016)</i>, pp. 265&ndash;266, Mar 2016.  DOI: <a target="_blank"                 href="https://doi.org/10.1109/VR.2016.7504755">10.1109/VR.2016.7504755</a>.</p>
<h3>Download</h3>
<p><a href="papers/2016_Plopski-etal_Spatial-Consistency-Perception_IEEE-VR.pdf">[PDF]</a>&nbsp;</p>
<h3>Abstract</h3>
<p class="abstract">  Correct spatial alignment is an essential requirement for convincingaugmented reality experiences. Registration error, caused by a varietyof systematic, environmental, and user influences decreases therealism and utility of head mounted display AR applications. Focus isoften given to rigorous calibration and prediction methods seeking toentirely remove misalignment error between virtual and realcontent. Unfortunately, producing perfect registration is often simplynot possible. Our goal is to quantify the sensitivity of users toregistration error in these systems, and identify acceptabilitythresholds at which users can no longer distinguish between thespatial positioning of virtual and real objects. We simulate bothvideo see-through and optical see-through environments using aprojector system and experimentally measure user perception of virtualcontent misalignment. Our results indicate that users are lessperceptive to rotational errors over all and that translationalaccuracy is less important in optical see-through systems than invideo see-through.</p>
<a href="IEEEVR-scp.bib"><h3>BibTeX</h3></a><pre>@InProceedings{IEEEVR-scp, 
  author =      {Alexander Plopski and Kenneth R. Moser and Kiyoshi Kiyokawa and 
                 J. Edward {Swan~II} and Haruo Takemura},
  title =       {Spatial Consistency Perception in Optical and Video
                 See-Through Head-Mounted Augmentations}, 
  booktitle =   {Poster Abstracts, IEEE International Conference on Virtual Reality 
                 (IEEE VR 2016)}, 
  location =    {Clemson, South Carolina, USA}, 
  date =        {March 19--23}, 
  month =       {Mar}, 
  year =        2016, 
  pages =       {265--266}, 
  note =        {DOI: &lt;a target="_blank"
                 href="https://doi.org/10.1109/VR.2016.7504755"&gt;10.1109/VR.2016.7504755&lt;/a&gt;.}, 
  abstract =    { 
Correct spatial alignment is an essential requirement for convincing
augmented reality experiences. Registration error, caused by a variety
of systematic, environmental, and user influences decreases the
realism and utility of head mounted display AR applications. Focus is
often given to rigorous calibration and prediction methods seeking to
entirely remove misalignment error between virtual and real
content. Unfortunately, producing perfect registration is often simply
not possible. Our goal is to quantify the sensitivity of users to
registration error in these systems, and identify acceptability
thresholds at which users can no longer distinguish between the
spatial positioning of virtual and real objects. We simulate both
video see-through and optical see-through environments using a
projector system and experimentally measure user perception of virtual
content misalignment. Our results indicate that users are less
perceptive to rotational errors over all and that translational
accuracy is less important in optical see-through systems than in
video see-through.
}, 
} 
</pre>
</div>
</div></div></body>
</html>
