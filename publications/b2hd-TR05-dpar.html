<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html lang="en" xml:lang="en">
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="StyleSheet" href="../css/responsive.css" type="text/css" media="all">
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>J. Edward Swan II</title>
</head>
<body><div class="outer_wrapper"><div class="inner_wrapper">
<div class="header"><p>J. Edward Swan II</p></div>
<div class="menu">
<ul>
<li><a href="../index.html"><em>A</em>BOUT</a></li> •
           <li><a href="../research.html"><em>R</em>ESEARCH</a></li> •
           <li><a href="sort_date.html" class="selected"><em>P</em>UBLICATIONS</a></li> •
           <li><a href="../teaching.html"><em>T</em>EACHING</a></li> •
           <li><a href="../tutorials.html"><em>T</em>UTORIALS</a></li> •
           <li><a href="../students.html"><em>S</em>TUDENTS</a></li>
</ul>
<p> </p>
</div>
<div class="content">
<ul class="h_list">
<li><big>• <a href="class_rescat.html">Classified by Research Category</a> </big></li>
<li><big>• <a href="class_type.html">Classified by Publication Type</a> </big></li>
<li><big>• <a href="sort_date.html">Classified by Date</a> </big></li>
</ul>
<h2> A Methodology for Quantifying Medium- and Far-Field Depth Perception in                  Optical, See-Through Augmented Reality</h2>
<p class="citation"> J. Edward Swan&nbsp;II,  Mark A. Livingston,  Harvey S. Smallman,  Joseph L. Gabbard,  Dennis Brown,  Yohan Biallot,  Simon J. Julier,  Greg S. Schmidt,  Catherine Zanbaka,  Deborah Hix, and  Lawrence Rosenblum.  A Methodology for Quantifying Medium- and Far-Field Depth Perception in                  Optical, See-Through Augmented Reality.  Technical Report #MSU-050531,  Department of Computer Science and Engineering, Mississippi State University, 2005.</p>
<h3>Download</h3>
<p><a href="papers/2005_Swan-etal_Depth-Perception-AR_TR-CSE.pdf">[PDF]</a>&nbsp;</p>
<h3>Abstract</h3>
<p class="abstract">  A fundamental problem in optical, see-through augmented reality (AR) is characterizing how it affects human depth perception.  This problem is important, because AR system developers need to both place graphics in arbitrary spatial relationships with real-world objects, and to know that users will perceive them in the same relationships.  However, achieving this is difficult, because the graphics are physically drawn directly in front of the eyes. Furthermore, AR makes possible enhanced perceptual techniques that have no real-world equivalent, such as x-ray vision, where AR users perceive that graphics are located behind opaque surfaces.  Also, to date AR depth perception research has examined near-field distances, yet many compelling AR applications operate at longer distances, and human depth perception itself operates differently at medium-field and far-field distances. This paper describes the first medium- and far-field AR depth perception experiment that provides metric results.  We describe a task and experimental design that measures AR depth perception, with strong linear perspective depth cues, and matches results found in the general depth perception literature.  Our experiment quantifies how depth estimation error grows with increasing distance across a range of medium- to far-field distances, and we also find evidence for a switch in bias from underestimating to overestimating depth at &nbsp;19.4 meters. Our experiment also examined the x-ray vision condition, and found initial evidence of how depth estimation error grows for occluded versus non-occluded graphics. </p>
<a href="TR05-dpar.bib"><h3>BibTeX</h3></a><pre>@TechReport{TR05-dpar, 
  author =      {J. Edward {Swan~II} and Mark A. Livingston and Harvey S. Smallman and 
                 Joseph L. Gabbard and Dennis Brown and Yohan Biallot and Simon J. Julier and 
                 Greg S. Schmidt and Catherine Zanbaka and Deborah Hix and Lawrence Rosenblum}, 
  title =       {A Methodology for Quantifying Medium- and Far-Field Depth Perception in 
                 Optical, See-Through Augmented Reality}, 
  type =        {Technical Report}, 
  number =      {#MSU-050531}, 
  institution = {Department of Computer Science and Engineering, Mississippi State University}, 
  month =       {May}, 
  year =        2005, 
  abstract =    { 
A fundamental problem in optical, see-through augmented reality (AR) is 
characterizing how it affects human depth perception.  This problem is 
important, because AR system developers need to both place graphics in arbitrary 
spatial relationships with real-world objects, and to know that users will 
perceive them in the same relationships.  However, achieving this is difficult, 
because the graphics are physically drawn directly in front of the eyes. 
Furthermore, AR makes possible enhanced perceptual techniques that have no 
real-world equivalent, such as x-ray vision, where AR users perceive that 
graphics are located behind opaque surfaces.  Also, to date AR depth perception 
research has examined near-field distances, yet many compelling AR applications 
operate at longer distances, and human depth perception itself operates 
differently at medium-field and far-field distances. 
This paper describes the first medium- and far-field AR depth perception 
experiment that provides metric results.  We describe a task and experimental 
design that measures AR depth perception, with strong linear perspective depth 
cues, and matches results found in the general depth perception literature.  Our 
experiment quantifies how depth estimation error grows with increasing distance 
across a range of medium- to far-field distances, and we also find evidence for 
a switch in bias from underestimating to overestimating depth at ~19.4 meters. 
Our experiment also examined the x-ray vision condition, and found initial 
evidence of how depth estimation error grows for occluded versus non-occluded 
graphics. 
}, 
} 
</pre>
</div>
</div></div></body>
</html>
