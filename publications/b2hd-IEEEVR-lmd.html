<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html lang="en" xml:lang="en">
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="StyleSheet" href="../css/responsive.css" type="text/css" media="all">
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>J. Edward Swan II</title>
</head>
<body><div class="outer_wrapper"><div class="inner_wrapper">
<div class="header"><p>J. Edward Swan II</p></div>
<div class="menu">
<ul>
<li><a href="../index.html"><em>A</em>BOUT</a></li> •
           <li><a href="../research.html"><em>R</em>ESEARCH</a></li> •
           <li><a href="sort_date.html" class="selected"><em>P</em>UBLICATIONS</a></li> •
           <li><a href="../teaching.html"><em>T</em>EACHING</a></li> •
           <li><a href="../tutorials.html"><em>T</em>UTORIALS</a></li> •
           <li><a href="../students.html"><em>S</em>TUDENTS</a></li>
</ul>
<p> </p>
</div>
<div class="content">
<ul class="h_list">
<li><big>• <a href="class_rescat.html">Classified by Research Category</a> </big></li>
<li><big>• <a href="class_type.html">Classified by Publication Type</a> </big></li>
<li><big>• <a href="sort_date.html">Classified by Date</a> </big></li>
</ul>
<h2> Leap Motion Hand and Stylus Tracking for Calibration and Interaction                  within Optical See-Through Augmented Reality</h2>
<p class="citation"> Kenneth R. Moser,  Sujan Anreddy, and  J. Edward Swan&nbsp;II.  Leap Motion Hand and Stylus Tracking for Calibration and Interaction                  within Optical See-Through Augmented Reality. In <i> Research Demonstrations, IEEE International Conference on Virtual Reality                  (IEEE VR 2016)</i>, Mar 2016.<br />  <a target="_blank" href="https://youtu.be/FCblJACs7sQ">                           https://youtu.be/FCblJACs7sQ</a></p>
<h3>Download</h3>
<p><a href="papers/2016_Moser-etal_SPAAM-Leap-Motion_IEEE-VR-Demo.pdf">[PDF]</a>&nbsp;</p>
<h3>Abstract</h3>
<p class="abstract">  Highly anticipated consumer level optical see-through head-mounted display offerings, such as the Microsoft HoloLens and Epson Moverio Pro BT-2000, include not only the standard IMU and GPS sensors common to modern mobile devices, but also feature additional depth sensing and hand tracking cameras intended to support and promote the development of innovative user interaction experiences. Through this demonstration, we showcase the potential of these technologies in facilitating not only interaction, but also intuitive user-centric calibration, for optical see-through augmented reality. Additionally, our hardware configuration provides a straightforward example for combining consumer level sensors, such as the Leap Motion controller, with existing head-mounted displays and secondary tracking devices to ease the development and deployment of immersive stereoscopic experiences. We believe that the methodologies presented within our demonstration not only illustrate the potential for ubiquitous calibration across next generation consumer devices, but will also inspire and encourage further developmental efforts for optical see-through augmented reality from the community at large. </p>
<a href="IEEEVR-lmd.bib"><h3>BibTeX</h3></a><pre>@InProceedings{IEEEVR-lmd, 
  author =      {Kenneth R. Moser and Sujan Anreddy and J. Edward {Swan~II}}, 
  title =       {Leap Motion Hand and Stylus Tracking for Calibration and Interaction 
                 within Optical See-Through Augmented Reality}, 
  booktitle =   {Research Demonstrations, IEEE International Conference on Virtual Reality 
                 (IEEE VR 2016)}, 
  location =    {Clemson, South Carolina, USA}, 
  date =        {March 19--23}, 
  month =       {Mar}, 
  year =        2016, 
  abstract = { 
Highly anticipated consumer level optical see-through head-mounted 
display offerings, such as the Microsoft HoloLens and Epson Moverio 
Pro BT-2000, include not only the standard IMU and GPS sensors common 
to modern mobile devices, but also feature additional depth sensing 
and hand tracking cameras intended to support and promote the 
development of innovative user interaction experiences. Through this 
demonstration, we showcase the potential of these technologies in 
facilitating not only interaction, but also intuitive user-centric 
calibration, for optical see-through augmented reality. Additionally, 
our hardware configuration provides a straightforward example for 
combining consumer level sensors, such as the Leap Motion controller, 
with existing head-mounted displays and secondary tracking devices to 
ease the development and deployment of immersive stereoscopic 
experiences. We believe that the methodologies presented within our 
demonstration not only illustrate the potential for ubiquitous 
calibration across next generation consumer devices, but will also 
inspire and encourage further developmental efforts for optical 
see-through augmented reality from the community at large. 
}, 
  wwwnote =              {&lt;a target="_blank" href="https://youtu.be/FCblJACs7sQ"&gt; 
                          https://youtu.be/FCblJACs7sQ&lt;/a&gt;}, 
} 
</pre>
</div>
</div></div></body>
</html>
